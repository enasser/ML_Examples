{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivor Prediction using Weka \n",
    "\n",
    "This notebook requires a Java kernal. This notebook uses Weka library for training, testing and verification of Titanic survivor dataset.\n",
    "\n",
    "NOTE:\n",
    "\n",
    "I have used IJAVA to create the Java Kernal. Java 9 or higher JDK is required for IJAVA which internally uses jshell.\n",
    "\n",
    "IJAVA - Jupyter kernel for executing Java code\n",
    "https://github.com/SpencerPark/IJava\n",
    "\n",
    "Install IJAVA using  the archive from https://github.com/SpencerPark/IJava/releases/download/v1.1.2/ijava-1.1.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<!-- Download the weka library from maven repository -->\n",
    "\n",
    "<!-- https://mvnrepository.com/artifact/nz.ac.waikato.cms.weka/weka-stable -->\n",
    "<dependency>\n",
    "\t<groupId>nz.ac.waikato.cms.weka</groupId>\n",
    "\t<artifactId>weka-stable</artifactId>\n",
    "\t<version>3.6.13</version>\n",
    "</dependency>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Import the required classes to the notebook. \n",
    " */\n",
    "\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.util.Arrays;\n",
    "import java.util.Enumeration;\n",
    "import java.util.List;\n",
    "\n",
    "import weka.classifiers.Classifier;\n",
    "import weka.classifiers.Evaluation;\n",
    "import weka.classifiers.evaluation.EvaluationUtils;\n",
    "import weka.classifiers.trees.BFTree;\n",
    "import weka.classifiers.trees.RandomForest;\n",
    "import weka.core.Attribute;\n",
    "import weka.core.Instance;\n",
    "import weka.core.Instances;\n",
    "import weka.core.SerializationHelper;\n",
    "import weka.core.converters.ArffLoader;\n",
    "import weka.core.converters.CSVLoader;\n",
    "import weka.core.converters.CSVSaver;\n",
    "import weka.core.converters.Loader;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GenericPropertiesCreator] classloader in use is not the system classloader: using static entries in weka/gui/GenericObjectEditor.props rather than dynamic class discovery.\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    " * Let us load the training dataset first. Set the attributes types\n",
    " * to the loader as weka understand only the ARFF format.\n",
    " * \n",
    " * The following are the columns in train and test datasets.\n",
    " * @attribute survived {0,1}\n",
    " * @attribute pclass numeric\n",
    " * @attribute name string\n",
    " * @attribute sex {male,female}\n",
    " * @attribute age numeric\n",
    " * @attribute sibsp numeric\n",
    " * @attribute parch numeric\n",
    " * @attribute ticket string\n",
    " * @attribute fare numeric\n",
    " * @attribute cabin string\n",
    " * @attribute embarked {Q,S,C}\n",
    " * \n",
    " * Columns 1,4 & 11 are nominal type, columns 3, 8 & 10 are string\n",
    " * type and the remaining integer types. Set the attribute types for\n",
    " * string and nominal data types, others are taken as integer.\n",
    " */\n",
    "CSVLoader trainCsvLoader = new CSVLoader();\n",
    "trainCsvLoader.setSource(new File(\"survivor_predict/train.csv\"));\n",
    "trainCsvLoader.setStringAttributes(\"3,8,10\");\n",
    "trainCsvLoader.setNominalAttributes(\"1,4,11\");\n",
    "Instances trainDataSet = trainCsvLoader.getDataSet();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Identify the label. Here, survived is the label\n",
    " * we want to predict.\n",
    " */\n",
    "Attribute trainAttribute = trainDataSet.attribute(0);\n",
    "trainDataSet.setClass(trainAttribute);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    " * The string attributes are not contributing features for prediction.\n",
    " * Also, RandomForest cannot handle string type. Hence, removing\n",
    " * them before training.\n",
    " */\n",
    "trainDataSet.deleteStringAttributes();\n",
    "trainDataSet.numAttributes();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Create a RandForest classifier and configure it.\n",
    " */\n",
    "RandomForest classifier = new RandomForest();\n",
    "classifier.setNumTrees(500);\n",
    "//classifier.setDebug(true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Train the classifier and create the prediction model.\n",
    " */\n",
    "classifier.buildClassifier(trainDataSet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the trained model as titanic_survivor_prediction.model\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    " * Save the model for future prediction.\n",
    " */\n",
    "SerializationHelper.write(\"survivor_predict/titanic_survivor_prediction.model\", classifier);\n",
    "System.out.println(\"Saved the trained model as titanic_survivor_prediction.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    " * Now load the test data to verify the model.\n",
    " * Set attribute types and remove string attributes.\n",
    " */\n",
    "CSVLoader testCsvLoader = new CSVLoader();\n",
    "testCsvLoader.setSource(new File(\"survivor_predict/test.csv\"));\n",
    "\n",
    "testCsvLoader.setStringAttributes(\"3,8,10\");\n",
    "testCsvLoader.setNominalAttributes(\"1,4,11\");\n",
    "Instances testDataSet = testCsvLoader.getDataSet();\n",
    "\n",
    "testDataSet.deleteStringAttributes();\n",
    "testDataSet.numAttributes();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Create a copy of the test dataset to store the predicted value.\n",
    " */\n",
    "CSVLoader testCsvLoader = new CSVLoader();\n",
    "testCsvLoader.setSource(new File(\"survivor_predict/test.csv\"));\n",
    "\n",
    "testCsvLoader.setStringAttributes(\"3,8,10\");\n",
    "testCsvLoader.setNominalAttributes(\"1,4,11\");\n",
    "Instances predictDataSet = testCsvLoader.getDataSet();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    " * Set the label for test and predict dataset. The remaining is taken as features.\n",
    " */\n",
    "Attribute testAttribute = testDataSet.attribute(0);\n",
    "testDataSet.setClass(testAttribute);\n",
    "\n",
    "Attribute predictAttribute = predictDataSet.attribute(0);\n",
    "predictDataSet.setClass(predictAttribute);\n",
    "\n",
    "predictDataSet.numAttributes();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Read the serialized model from disk for verification.\n",
    " */\n",
    "Classifier classifier = (Classifier) SerializationHelper\n",
    "                            .read(\"survivor_predict/titanic_survivor_prediction.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Iterate over the test data, classify each entry and set the\n",
    " * value of the 'survived' column of predict dataset with the result \n",
    " * of the classification\n",
    " */\n",
    "Enumeration testInstances = testDataSet.enumerateInstances();\n",
    "Enumeration predictInstances = predictDataSet.enumerateInstances();\n",
    "while (testInstances.hasMoreElements()) {\n",
    "    Instance testInstance = (Instance) testInstances.nextElement();\n",
    "    Instance predictInstance = (Instance) predictInstances.nextElement();\n",
    "    \n",
    "    double classification = classifier.classifyInstance(testInstance);\n",
    "    predictInstance.setClassValue(classification);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicited output dataset written as survivor_predict/titanic_survivor_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    " * Write the predicted output dataset to disk. \n",
    " */\n",
    "CSVSaver predictedCsvSaver = new CSVSaver();\n",
    "predictedCsvSaver.setFile(new File(\"survivor_predict/titanic_survivor_prediction.csv\"));\n",
    "predictedCsvSaver.setInstances(predictDataSet);\n",
    "predictedCsvSaver.writeBatch();\n",
    "\n",
    "System.out.println(\"Predicited output dataset written as survivor_predict/titanic_survivor_prediction.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[D@6a2d79ac"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    " * Evaluate the performance of the classifier model.\n",
    " * Make the predict dataset columns same as training dataset\n",
    " * for evaluation.\n",
    " */\n",
    "predictDataSet.deleteStringAttributes();\n",
    "\n",
    "Evaluation evaluation = new Evaluation(trainDataSet);\n",
    "evaluation.evaluateModel(classifier, predictDataSet, new Object[] {});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest of 500 trees, each constructed while considering 3 random features.\n",
      "Out of bag error: 0.1796\n",
      "\n",
      "\n",
      "\n",
      "Correctly Classified Instances         418              100      %\n",
      "Incorrectly Classified Instances         0                0      %\n",
      "Kappa statistic                          1     \n",
      "Mean absolute error                      0.1949\n",
      "Root mean squared error                  0.239 \n",
      "Relative absolute error                 41.9483 %\n",
      "Root relative squared error             50.058  %\n",
      "Total Number of Instances              418     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    " * Print the details of classifier and evaluation summary.\n",
    " */\n",
    "System.out.println(classifier);\n",
    "System.out.println(evaluation.toSummaryString());\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "10.0.2-adoptopenjdk+13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
