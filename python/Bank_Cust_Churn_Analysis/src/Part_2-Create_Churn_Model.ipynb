{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"http://milepro.com/wp-content/uploads/2014/01/Travel-Credit-Cards-1024x606.jpg\" style=\"width:200px; float: left; padding-right: 10px\"/>\n",
    "<h2 style=\"font-face: verdana; font-size: 32px;\">Predict credit card customer churn<br>with IBM Watson Machine Learning</h2>\n",
    "<h3 style=\"font-face: verdana; font-size: 16px;\">Part 2: Create Churn Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1. Load the data into a dataframe ##\n",
    "-------------------------------------\n",
    "<p>In this section you will load the data as an Apache® Spark DataFrame and perform a basic exploration.</p>\n",
    "<p>Load the data from the DB2 table to the Spark DataFrame using JDBC driver.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009520380, u'F', 59, 1, 0.0, 18267.0, 0, 0, 7957.1406, 0.654795, 239, 33.0, 2, u'ME', u'High school graduate', 0, u'FALSE')\n"
     ]
    }
   ],
   "source": [
    "import jaydebeapi, sys\n",
    "\n",
    "#Enter the values for you database connection\n",
    "dsn_database = \"XXXX\"            # e.g. “BLUDB” Name of the database\n",
    "dsn_hostname = \"X.XX.XXX.XX\" # e.g.: “bluemix05.bluforcloud.com”\n",
    "dsn_port = \"XXXXX\"                # e.g. “50000\" Database port number\n",
    "dsn_uid = \"XXXXXXXX\"        # e.g. “dash104434\" User id\n",
    "dsn_pwd = \"XXXXXXXX\"       # e.g. “7dBZ3jWt9xN6$o0JiX!m” User password for the database\n",
    "\n",
    "connection_string='jdbc:db2://'+dsn_hostname+':'+dsn_port+'/'+dsn_database\n",
    "if (sys.version_info >= (3,0)):\n",
    "    conn = jaydebeapi.connect(\"com.ibm.db2.jcc.DB2Driver\", connection_string, [dsn_uid, dsn_pwd])\n",
    "else:\n",
    "    conn = jaydebeapi.connect(\"com.ibm.db2.jcc.DB2Driver\", [connection_string, dsn_uid, dsn_pwd])\n",
    "\n",
    "curs = conn.cursor()\n",
    "curs.execute(\"select * from XXX.XXXXXXXX\")\n",
    "list1 = curs.fetchall()\n",
    "print(list1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CUST_ID=1009520380, SEX=u'F', AGE=59, EDUCATION=1, INVESTMENT=0.0, INCOME=18267.0, ACTIVITY=0, CHURN=0, YRLY_AMT=7957.1406, AVG_DAILY_TX=0.654795, YRLY_TX=239, AVG_TX_AMT=33.0, NEGTWEETS=2, STATE=u'ME', EDUCATION_GROUP=u'High school graduate', TWITTERID=0, CHURN_LABEL=u'FALSE'),\n",
       " Row(CUST_ID=1009520400, SEX=u'M', AGE=50, EDUCATION=1, INVESTMENT=0.0, INCOME=17867.0, ACTIVITY=2, CHURN=0, YRLY_AMT=7946.078, AVG_DAILY_TX=0.660274, YRLY_TX=241, AVG_TX_AMT=32.0, NEGTWEETS=4, STATE=u'UT', EDUCATION_GROUP=u'High school graduate', TWITTERID=0, CHURN_LABEL=u'FALSE'),\n",
       " Row(CUST_ID=1009520410, SEX=u'F', AGE=53, EDUCATION=1, INVESTMENT=0.0, INCOME=17576.0, ACTIVITY=1, CHURN=0, YRLY_AMT=7961.8086, AVG_DAILY_TX=0.663014, YRLY_TX=242, AVG_TX_AMT=32.0, NEGTWEETS=4, STATE=u'AK', EDUCATION_GROUP=u'High school graduate', TWITTERID=0, CHURN_LABEL=u'FALSE'),\n",
       " Row(CUST_ID=1009520420, SEX=u'F', AGE=48, EDUCATION=3, INVESTMENT=90419.0, INCOME=111569.0, ACTIVITY=5, CHURN=0, YRLY_AMT=26803.0, AVG_DAILY_TX=0.794521, YRLY_TX=290, AVG_TX_AMT=92.0, NEGTWEETS=3, STATE=u'LA', EDUCATION_GROUP=u'Masters degree', TWITTERID=0, CHURN_LABEL=u'FALSE'),\n",
       " Row(CUST_ID=1009520430, SEX=u'M', AGE=48, EDUCATION=2, INVESTMENT=11258.0, INCOME=20142.0, ACTIVITY=1, CHURN=1, YRLY_AMT=8800.02, AVG_DAILY_TX=0.654795, YRLY_TX=239, AVG_TX_AMT=36.0, NEGTWEETS=7, STATE=u'MD', EDUCATION_GROUP=u'Bachelors degree', TWITTERID=0, CHURN_LABEL=u'TRUE')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.createDataFrame(list1, ['CUST_ID', 'SEX', 'AGE', 'EDUCATION', 'INVESTMENT', 'INCOME', 'ACTIVITY', 'CHURN', 'YRLY_AMT', 'AVG_DAILY_TX', 'YRLY_TX', 'AVG_TX_AMT', 'NEGTWEETS', 'STATE','EDUCATION_GROUP', 'TWITTERID', 'CHURN_LABEL'])\n",
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "### 1.2 Select Churn Data for the Model ###\n",
    "<p>Select AGE, ACTIVITY, EDUCATION, SEX, STATE, NEGTWEETS, INCOME, CHURN from the churnDataRaw dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(AGE=59, ACTIVITY=0, EDUCATION=1, SEX=u'F', STATE=u'ME', NEGTWEETS=2, INCOME=18267.0, CHURN=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData = df.select('AGE', 'ACTIVITY', 'EDUCATION', 'SEX', 'STATE', 'NEGTWEETS', 'INCOME', 'CHURN')\n",
    "churnData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## 2. Create an Apache Spark machine learning model ##\n",
    "-------------------------------------\n",
    "<p>Prepare data, create an Apache Spark machine learning pipeline, and train a model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 2.1 Prepare the Data ###\n",
    "<p>In this subsection you will split your data into: train, test and predict datasets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(AGE=20, ACTIVITY=2, EDUCATION=2, SEX=u'M', STATE=u'CA', NEGTWEETS=6, INCOME=25513.0, CHURN=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF, validateDF, testDF = churnData.randomSplit([.7,.15,.15])\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(AGE=20, ACTIVITY=3, EDUCATION=1, SEX=u'F', STATE=u'ID', NEGTWEETS=3, INCOME=20549.0, CHURN=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(AGE=22, ACTIVITY=1, EDUCATION=4, SEX=u'M', STATE=u'PA', NEGTWEETS=3, INCOME=58691.0, CHURN=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validateDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 2.2 Create pipeline and train a model ###\n",
    "<p>In this section you will create an Apache® Spark machine learning pipeline and then train the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "genderIndexer = StringIndexer(inputCol=\"SEX\", outputCol=\"gender_code\")\n",
    "stateIndexer = StringIndexer(inputCol=\"STATE\", outputCol=\"state_code\")\n",
    "featuresAssembler = VectorAssembler(\n",
    "    inputCols=[\"AGE\", \"ACTIVITY\",\"EDUCATION\",\"NEGTWEETS\",\"INCOME\",\"gender_code\",\"state_code\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Next, define estimators you want to use for classification. Logistics Regression is used in the following example.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(regParam=0.01, labelCol=\"CHURN\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Setup a Cognitive Assistant for Data Scientists - predict model performance based on sampled data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[genderIndexer, stateIndexer, featuresAssembler, lr])\n",
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>You can check your model accuracy now. To evaluate the model, use test data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.986998916576\n",
      "Test Error = 0.0130010834236\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions = model.transform(testDF)\n",
    "evaluatorRF = MulticlassClassificationEvaluator(labelCol=\"CHURN\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluatorRF.evaluate(predictions)\n",
    "print \"Accuracy = \" + str(accuracy)\n",
    "print \"Test Error = \" + str(1.0 - accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (1.0, 1.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsAndLabels = predictions.rdd.map(lambda r: (float(r.prediction),float(r['CHURN'])))\n",
    "predictionsAndLabels.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate metrics object\n",
    "metrics = BinaryClassificationMetrics(predictionsAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.978145720041\n",
      "Area under ROC = 0.977936415231\n"
     ]
    }
   ],
   "source": [
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "\n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<p>Create a true positive and false positive rate</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pR = [(1.0,1.0)]\n",
    "for i in np.arange(0.0, 1.01, 0.01):\n",
    "    preds = predictions.rdd.map(lambda r: (float(r['probability'][1]>i),float(r['CHURN']),r['probability']))\n",
    "    tp = float(preds.filter(lambda r: r[0] == 1.0 and r[1] == 1.0).count())\n",
    "    fp = float(preds.filter(lambda r: r[0] == 1.0 and r[1] == 0.0).count())\n",
    "    fn = float(preds.filter(lambda r: r[0] == 0.0 and r[1] == 1.0).count())\n",
    "    tn = float(preds.filter(lambda r: r[0] == 0.0 and r[1] == 0.0).count())\n",
    "    if tp == 0.0 and fp == 0.0:\n",
    "        pR.append((0.0,0.0))\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "        falsePosRate = fp/(fp+tn)\n",
    "        pR.append((falsePosRate,recall))\n",
    "pR.append((0.0,0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<p>Load the rocCurve into a dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "rocDF = pd.DataFrame(pR)\n",
    "rocDF = rocDF.rename(index=str, columns={0: \"FalsePositiveRate\", 1: \"TruePositiveRate\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## 3. Watson Machine Learning - Use Repository service to save model. ##\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from repository.mlrepositoryclient import MLRepositoryClient\n",
    "from repository.mlrepositoryartifact import MLRepositoryArtifact\n",
    "from repository.mlrepository import MetaProps, MetaNames\n",
    "\n",
    "ml_repository_client = MLRepositoryClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inputDataSchema', 'description', 'modelVersionHref', 'authorUID', 'creationTime', 'lastUpdated', 'label', 'trainingDataSchema', 'version', 'modelType', 'runtime']\n",
      "\n",
      "modelType: spark-2.0\n",
      "trainingDataSchema: [{'type': 'bigint', 'name': 'AGE'}, {'type': 'bigint', 'name': 'ACTIVITY'}, {'type': 'bigint', 'name': 'EDUCATION'}, {'type': 'string', 'name': 'SEX'}, {'type': 'string', 'name': 'STATE'}, {'type': 'bigint', 'name': 'NEGTWEETS'}, {'type': 'double', 'name': 'INCOME'}, {'type': 'bigint', 'name': 'CHURN'}]\n",
      "creationTime: 1523925534681\n",
      "modelVersionHref: https://dsxl-api.ibm-private-cloud.svc.cluster.local/v3/project/Bank_Cust_Churn_Analysis/models/Banking%20customer%20Churn/2\n",
      "label: CHURN\n"
     ]
    }
   ],
   "source": [
    "model_artifact = MLRepositoryArtifact(model, training_data=trainDF, name=\"Banking customer Churn\")\n",
    "\n",
    "saved_model = ml_repository_client.models.save(model_artifact)\n",
    "\n",
    "print saved_model.meta.available_props()\n",
    "print\n",
    "print \"modelType: \" + saved_model.meta.prop(\"modelType\")\n",
    "print \"trainingDataSchema: \" + str(saved_model.meta.prop(\"trainingDataSchema\"))\n",
    "print \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\n",
    "print \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\n",
    "print \"label: \" + saved_model.meta.prop(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Tip: modelVersionHref is our model unique indentifier in the Watson Machine Learning repository.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Get saved model metadata from Watson Machine Learning.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputDataSchema',\n",
       " 'description',\n",
       " 'modelVersionHref',\n",
       " 'authorUID',\n",
       " 'creationTime',\n",
       " 'lastUpdated',\n",
       " 'label',\n",
       " 'trainingDataSchema',\n",
       " 'version',\n",
       " 'modelType',\n",
       " 'runtime']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.meta.available_props()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 3.2 Load model and make predictions ##\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banking customer Churn\n",
      "/user-home/999/DSX_Projects/Bank_Cust_Churn_Analysis/models/Banking customer Churn/2\n"
     ]
    }
   ],
   "source": [
    "print(loadedModelArtifact.name)\n",
    "print(saved_model.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = loadedModelArtifact.model_instance().transform(validateDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------+---+-----+---------+-------+-----+\n",
      "|AGE|ACTIVITY|EDUCATION|SEX|STATE|NEGTWEETS| INCOME|CHURN|\n",
      "+---+--------+---------+---+-----+---------+-------+-----+\n",
      "| 22|       1|        4|  M|   PA|        3|58691.0|    0|\n",
      "| 23|       3|        4|  M|   PA|        3|21773.0|    0|\n",
      "| 24|       5|        4|  M|   VA|        5|17830.0|    0|\n",
      "| 25|       2|        4|  M|   FL|        4|59970.0|    0|\n",
      "| 25|       2|        4|  M|   ID|       13|17191.0|    1|\n",
      "| 25|       5|        1|  F|   MO|        4|16043.0|    0|\n",
      "| 26|       0|        4|  M|   MI|       16|13552.0|    1|\n",
      "| 26|       4|        1|  F|   ID|        3|18071.0|    0|\n",
      "| 27|       2|        1|  M|   NM|        3|21619.0|    0|\n",
      "| 27|       2|        4|  M|   WA|       11|29404.0|    1|\n",
      "| 28|       2|        1|  F|   MI|        8|25604.0|    1|\n",
      "| 28|       2|        1|  M|   ID|        7|19226.0|    1|\n",
      "| 28|       5|        4|  F|   WA|        9|20550.0|    1|\n",
      "| 29|       2|        1|  M|   CO|        3|22616.0|    0|\n",
      "| 30|       0|        2|  M|   ID|        9|36901.0|    1|\n",
      "| 31|       0|        1|  M|   PA|        8|21221.0|    1|\n",
      "| 31|       1|        1|  F|   ND|       11|15886.0|    1|\n",
      "| 31|       2|        4|  F|   TX|        5|15291.0|    0|\n",
      "| 31|       3|        2|  M|   IA|        3|28665.0|    0|\n",
      "| 31|       4|        1|  F|   TX|        2|17531.0|    0|\n",
      "+---+--------+---------+---+-----+---------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"AGE\",\"ACTIVITY\",\"EDUCATION\",\"SEX\",\"STATE\",\"NEGTWEETS\",\"INCOME\",\"CHURN\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 with Spark Local Mode",
   "language": "python",
   "name": "py2localspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
